# Name: extract_exploit_ref.py
# Author: Mark Rumsey
# Date: 05/23/23
# Description: Mines all existing CVEs on NVD and saves output into 2 files:
#   1. exploits_{timestamp}.csv - CVE_id, url, http_response_status
#   2. exploit_hosts_{timestamp}.csv - hostname, frequency, http_response_status

import requests
import gzip
import json
import csv
import re
from datetime import datetime
import concurrent.futures
import functools

YEAR = 2023         # current year
N_THREADS = 50      # number of threads to send requests

def mineCVEs():

    urls = ['https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-modified.json.gz',
            'https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-recent.json.gz']
    
    # get URL for each year
    for year in range(YEAR, 2001, -1):
        urls.append(f'https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-{year}.json.gz')

    data = []
    for url in urls:

        # download file from URL
        print(f'Downloading {url[40:-3]}')
        gz_file = requests.get(url).content

        # decompress GZIP file
        decompressed_file = gzip.decompress(gz_file)

        # load file contents as JSON 
        json_data = json.loads(decompressed_file)
        data.append(json_data)
        print(f'{url[40:-3]} successfully downloaded')
        print()

    return data

def get_exploits(data):

    domains = {}
    exploits = {}

    for json_file in data:

        for entry in json_file['CVE_Items']:

            # get CVE id
            id = entry['cve']['CVE_data_meta']['ID']

            # loop over references and save URLs tagged as exploit
            for ref in entry['cve']['references']['reference_data']:

                if 'Exploit' in ref['tags']:

                    # get domain using regex
                    domain = re.match('^(?:https?:\/\/)?(?:[^@\/\n]+@)?(?:www\.)?([^:\/?\n]+)', ref['url'])

                    # create dictionary entry for domain if it does not yet exist
                    if domain.group(1) not in domains:
                        domains[domain.group(1)] = {'freq': 1, 'url': domain.group(0)}

                    # increment frequency if already exists
                    else:
                        domains[domain.group(1)]['freq'] += 1

                    exploits[id] = {'url': ref['url']}

    return domains, exploits

def send_requests(domains, exploits):

    # create functions for domains and exploits dictionaries
    get_status_domains = functools.partial(get_status, dictionary=domains)
    get_status_exploits = functools.partial(get_status, dictionary=exploits)

    # send head requests to urls concurrently
    with concurrent.futures.ThreadPoolExecutor(max_workers=N_THREADS) as executor:
        executor.map(get_status_domains, domains)

    with concurrent.futures.ThreadPoolExecutor(max_workers=N_THREADS) as executor:
        executor.map(get_status_exploits, exploits)

def get_status(key, dictionary):

    url = dictionary[key]['url']

    # get response status
    try:
        status = requests.head(url, timeout=5).status_code
    except requests.exceptions.ReadTimeout:                     # took too long to respond
        status = 'TIMEOUT'
    except requests.exceptions.ConnectionError:                 # network error
        status = 'CONNECTION_ERROR'
    except requests.exceptions.MissingSchema:                   # not a valid url
        status = 'INVALID_URL'
    except requests.exceptions.RequestException:                # other error
        status = 'ERROR'

    # save status in dictionary
    dictionary[key]['status'] = status
    print(f'{url} - {status}')

def main():

    # download CVE data from NVD
    data = mineCVEs()
    domains, exploits = get_exploits(data)

    # send head requests to urls
    send_requests(domains, exploits)

    # create file with timestamp
    now = str(datetime.now()).replace(' ', '_')
    outfile = open(f'exploits_{now}.csv', 'w')
    writer = csv.writer(outfile)

    # write header to CSV
    header = ['CVE_id', 'exploit_url', 'status']
    writer.writerow(header)

    # write data to CSV
    for cve in exploits:
        writer.writerow([cve, exploits[cve]['url'], exploits[cve]['status']])
    outfile.close()

    # create hostnames file with timestamp
    hosts_file = open(f'exploit_hosts_{now}.csv', 'w')
    writer = csv.writer(hosts_file)

    # write header to CSV
    header = ['hostname', 'frequency', 'status']
    writer.writerow(header)

    # write data to CSV
    for hostname in domains:
        writer.writerow([hostname, domains[hostname]['freq'], domains[hostname]['status']])
    hosts_file.close()

if __name__ == '__main__':
    main()