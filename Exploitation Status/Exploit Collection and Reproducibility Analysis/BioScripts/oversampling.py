import pandas as pd
import numpy as np
from sklearn.utils import shuffle

# Load the data
data = pd.read_csv("balanced_formatted.csv")

# Dynamically get the tag counts
tag_counts = data[data.Tag.str.startswith("B-")]["Tag"].value_counts().to_dict()

# Given max_count (you could also calculate it dynamically)
max_count = max(tag_counts.values())

# Identify minority tags to oversample
minority_tags = {tag: count for tag, count in tag_counts.items() if count < max_count * 0.8}

oversampled_data = [data]

for tag, count in minority_tags.items():
    # Calculate how many times to duplicate each sentence with the minority tag
    multiplier = int(max_count / count)
    
    # Filter sentences for the current minority tag
    minority_sentences = data[data["Tag"] == tag]
    
    # Duplicate the sentences
    oversampled_sentences = pd.concat([minority_sentences] * multiplier, ignore_index=True)
    
    # Shuffle the oversampled sentences to avoid sequence bias
    oversampled_sentences = shuffle(oversampled_sentences)
    
    # Add to oversampled data
    oversampled_data.append(oversampled_sentences)

# Combine all the data together
oversampled_df = pd.concat(oversampled_data, ignore_index=True)

# Shuffle the entire dataset
oversampled_df = shuffle(oversampled_df)

# Save the oversampled data
oversampled_df.to_csv("oversampled_file.csv", index=False)
