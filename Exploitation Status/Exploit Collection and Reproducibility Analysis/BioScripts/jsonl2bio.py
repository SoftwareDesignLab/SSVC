# Proof of Concept and Steps to Reproduce -> 'O'

import json
import csv
import re

def map_labels(label):
    label_mapping = {
        'Published dates': 'Published_dates',
        'Host Information': 'Host_Information',
        'Proof of Concept': 'Proof_of_Concept',
        'Steps to Reproduce': 'Steps_to_Reproduce',
        'Version Number': 'Version_Number',
        'Vulnerability Type': 'Vulnerability_Type'
    }
    return label_mapping.get(label, label)


def extract_entities(text, entities):
    words = text.split()
    bio_labels = ['O'] * len(words)

    # Patterns to check for unlabeled host information
    host_info_patterns = [
        r'\bubuntu\b', r'\blinux\b', r'\bwindows\b', r'\bmacos\b',
        r'\bios\b', r'\bandroid\b'
    ]
    tested_on_pattern = r'Tested on\s+(\w+)'

    # Compile regex patterns
    cve_pattern = re.compile(r'\bCVE-\d+-\d+\b', re.IGNORECASE)
    cvss_pattern = re.compile(r'\b\d+(\.\d+)?\/[A-Z]{2}:[A-Z]\/[A-Z]{2}:[A-Z]\/[A-Z]{2}:[A-Z]\/[A-Z]{2}:[A-Z]\/[A-Z]{1}:[A-Z]\/[A-Z]{1}:[A-Z]\/[A-Z]{1}:[A-Z](,[A-Z])?\b')
    cwe_pattern = re.compile(r'\bCWE-\d+\b')
    host_info_patterns = [re.compile(pattern, re.IGNORECASE) for pattern in host_info_patterns]
    tested_on_pattern = re.compile(tested_on_pattern, re.IGNORECASE)

    # Check and label host information based on patterns
    def label_host_information(match, label):
        start_word_idx = len(text[:match.start()].split())
        end_word_idx = len(text[:match.end()].split())
        # Check index bounds before assignment
        if 0 <= start_word_idx < len(bio_labels) and 0 < end_word_idx <= len(bio_labels):
            if all(bio_labels[i] == 'O' for i in range(start_word_idx, end_word_idx)):
                bio_labels[start_word_idx] = 'B-' + label
                for i in range(start_word_idx + 1, end_word_idx):
                    bio_labels[i] = 'I-' + label

    # Check for unlabeled host information, CVSS scores, and CWE identifiers
    for pattern in host_info_patterns + [cvss_pattern, cwe_pattern]:
        for match in pattern.finditer(text):
            label = 'Host_Information' if pattern in host_info_patterns else 'Risk' if pattern == cvss_pattern else 'Vulnerability_Type'
            label_host_information(match, label)

    # Check for "Tested on" pattern and label the next word as 'Host_Information' if it is not already labeled
    for match in tested_on_pattern.finditer(text):
        if match.group(1):  # If there is a word following "Tested on"
            label_host_information(match, 'Host_Information')

    # Sort entities by start_offset to prevent overwriting
    entities = sorted(entities, key=lambda x: x['start_offset'])

    for entity in entities:
        label = map_labels(entity['label'])
        start_offset = entity['start_offset']
        end_offset = entity['end_offset']

        start_word_idx = len(text[:start_offset].split())
        end_word_idx = len(text[:end_offset].split())

        # Check if start_word_idx or end_word_idx exceeds the available word indices
        if start_word_idx >= len(bio_labels) or end_word_idx > len(bio_labels):
            continue 

        # Check if label is among those we want to ignore and set them to 'O'
        if label in ['Proof_of_Concept', 'Steps_to_Reproduce']:
            for i in range(start_word_idx, end_word_idx):
                bio_labels[i] = 'O'
        else:
            # Assigning BIO labels to labeled entities
            bio_labels[start_word_idx] = 'B-' + label
            for i in range(start_word_idx + 1, end_word_idx):
                bio_labels[i] = 'I-' + label

        # Handle specific cases like "CVE" pattern
        entity_text = ' '.join(words[start_word_idx:end_word_idx])
        if re.match(cve_pattern, entity_text):
            bio_labels[start_word_idx] = 'B-CVE'
            for i in range(start_word_idx + 1, end_word_idx):
                bio_labels[i] = 'I-CVE'

    return bio_labels

def convert_to_csv(jsonl_file, csv_file, invalid_json_file):
    with open(jsonl_file, 'r', encoding='utf-8') as f:
        annotations = []
        invalid_json_lines = []
        for line in f:
            try:
                annotation = json.loads(line.strip(), strict=False)
                annotations.append(annotation)
            except json.JSONDecodeError:
                invalid_json_lines.append(line)

    # Save invalid JSON lines to a separate file
    with open(invalid_json_file, 'w', encoding='utf-8') as f:
        f.writelines(invalid_json_lines)

    with open(csv_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['text', 'label'])

        for annotation in annotations:
            text = annotation['text']
            entities = annotation['entities']
        
            # Use the extract_entities function to get proper BIO labels
            bio_labels = extract_entities(text, entities)

            # Join words and labels into a single string with spaces and write to the CSV file
            text_with_labels = ' '.join([word for word in text.split()])
            labels = ' '.join([label for label in bio_labels])
            writer.writerow([text_with_labels, labels])

def create_multi_label_csv(jsonl_file, csv_file):
    with open(jsonl_file, 'r', encoding='utf-8') as f:
        annotations = []
        for line in f:
            annotation = json.loads(line.strip(), strict=False)
            annotations.append(annotation)

    with open(csv_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['doccano_id', 'label_1', 'label_2', 'csv_line', 'jsonl_line'])

        for idx, annotation in enumerate(annotations, start=1):  # JSONL starts on line 1
            text = annotation['text']
            entities = annotation['entities']
            doccano_id = annotation['id']

            labels = [entity['label'] for entity in entities]
            offsets = [(entity['start_offset'], entity['end_offset']) for entity in entities]

            for i in range(len(entities)):
                for j in range(i + 1, len(entities)):
                    if entities[i]['start_offset'] <= entities[j]['end_offset'] and entities[i]['end_offset'] >= entities[j]['start_offset']:
                        label_1 = labels[i]
                        label_2 = labels[j]

                        # Check if the overlapping labels are different
                        if label_1 != label_2:
                            csv_line = idx + 1  # CSV starts on line 2 due to header
                            jsonl_line = idx

                            writer.writerow([doccano_id, label_1, label_2, csv_line, jsonl_line])

if __name__ == '__main__':
    jsonl_file_name = 'dataset.jsonl'
    csv_file_name = 'ner.csv'
    multi_label_csv_file_name = 'multi_label.csv'
    invalid_json_file_name = 'invalid_json_lines.txt'

    convert_to_csv(jsonl_file_name, csv_file_name, invalid_json_file_name)
    create_multi_label_csv(jsonl_file_name, multi_label_csv_file_name)
