import json
import csv
import random
import pandas as pd
from collections import defaultdict
import re

def map_labels(label):
    label_mapping = {
        'Published dates': 'Published_dates',
        'Host Information': 'Host_Information',
        'Proof of Concept': 'Proof_of_Concept',
        'Steps to Reproduce': 'Steps_to_Reproduce',
        'Version Number': 'Version_Number',
        'Vulnerability Type': 'Vulnerability_Type',
    }
    return label_mapping.get(label, label)

def extract_entities(text, entities):
    words = text.split()
    bio_labels = ['O'] * len(words)

    # Patterns to check for unlabeled host information
    host_info_patterns = [
        r'\bubuntu\b', r'\blinux\b', r'\bwindows\b', r'\bmacos\b',
        r'\bios\b', r'\bandroid\b'
    ]
    tested_on_pattern = r'Tested on\s+(\w+)'

    # Compile regex patterns
    cve_pattern = re.compile(r'\bCVE-\d+-\d+\b', re.IGNORECASE)
    cvss_pattern = re.compile(r'\b\d+(\.\d+)?\/[A-Z]{2}:[A-Z]\/[A-Z]{2}:[A-Z]\/[A-Z]{2}:[A-Z]\/[A-Z]{2}:[A-Z]\/[A-Z]{1}:[A-Z]\/[A-Z]{1}:[A-Z]\/[A-Z]{1}:[A-Z](,[A-Z])?\b')
    cwe_pattern = re.compile(r'\bCWE-\d+\b')
    host_info_patterns = [re.compile(pattern, re.IGNORECASE) for pattern in host_info_patterns]
    tested_on_pattern = re.compile(tested_on_pattern, re.IGNORECASE)

    # Check and label host information based on patterns
    def label_host_information(match, label):
        start_word_idx = len(text[:match.start()].split())
        end_word_idx = len(text[:match.end()].split())
        # Check index bounds before assignment
        if 0 <= start_word_idx < len(bio_labels) and 0 < end_word_idx <= len(bio_labels):
            if all(bio_labels[i] == 'O' for i in range(start_word_idx, end_word_idx)):
                bio_labels[start_word_idx] = 'B-' + label
                for i in range(start_word_idx + 1, end_word_idx):
                    bio_labels[i] = 'I-' + label

    # Check for unlabeled host information, CVSS scores, and CWE identifiers
    for pattern in host_info_patterns + [cvss_pattern, cwe_pattern]:
        for match in pattern.finditer(text):
            label = 'Host_Information' if pattern in host_info_patterns else 'Risk' if pattern == cvss_pattern else 'Vulnerability_Type'
            label_host_information(match, label)

    # Check for "Tested on" pattern and label the next word as 'Host_Information' if it is not already labeled
    for match in tested_on_pattern.finditer(text):
        if match.group(1):  # If there is a word following "Tested on"
            label_host_information(match, 'Host_Information')

    # Sort entities by start_offset to prevent overwriting
    entities = sorted(entities, key=lambda x: x['start_offset'])

    for entity in entities:
        label = map_labels(entity['label'])
        start_offset = entity['start_offset']
        end_offset = entity['end_offset']

        start_word_idx = len(text[:start_offset].split())
        end_word_idx = len(text[:end_offset].split())

        # Check if start_word_idx or end_word_idx exceeds the available word indices
        if start_word_idx >= len(bio_labels) or end_word_idx > len(bio_labels):
            continue 

        # Check if label is among those we want to ignore and set them to 'O'
        if label in ['Proof_of_Concept', 'Steps_to_Reproduce']:
            for i in range(start_word_idx, end_word_idx):
                bio_labels[i] = 'O'
        else:
            # Assigning BIO labels to labeled entities
            bio_labels[start_word_idx] = 'B-' + label
            for i in range(start_word_idx + 1, end_word_idx):
                bio_labels[i] = 'I-' + label

        # Handle specific cases like "CVE" pattern
        entity_text = ' '.join(words[start_word_idx:end_word_idx])
        if re.match(cve_pattern, entity_text):
            bio_labels[start_word_idx] = 'B-CVE'
            for i in range(start_word_idx + 1, end_word_idx):
                bio_labels[i] = 'I-CVE'

    return bio_labels

def count_b_labels(csv_file):
    df = pd.read_csv(csv_file)
    total_b_labels = 0

    for label in df['label']:
        for string in label.split():
            if string.startswith('B-'):
                total_b_labels += 1
    
    return total_b_labels

def convert_to_csv(jsonl_file, csv_file, invalid_json_file, original_csv_file):
    num_b_labels = count_b_labels(original_csv_file)

    with open(jsonl_file, 'r', encoding='utf-8') as f:
        annotations = []
        invalid_json_lines = []
        for line in f:
            try:
                annotation = json.loads(line.strip(), strict=False)
                annotations.append(annotation)
            except json.JSONDecodeError:
                invalid_json_lines.append(line)

    # Save invalid JSON lines to a separate file
    with open(invalid_json_file, 'w', encoding='utf-8') as f:
        f.writelines(invalid_json_lines)

    with open(csv_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['text', 'label'])
        '''
        # first pass: count Bs, collect Os
        create dict mapping annotation number to indices of Os in that annotation
        for each annotation:
            add list/set of O indices to annotation number dict
        randomly sample O indices equal to num of Bs
        create new dict for O indices to keep 
        # second pass: form text from B indices and select O indices, insert into csv
        for each annotation:
            get text for Bs
            remove O indices from removing dict
            get text for remaining Os
            combine text to create csv row
            insert csv row
        '''
        o_ix_map = {}
        for ix, annotation in enumerate(annotations):
            text = annotation['text']
            entities = annotation['entities']
            bio_labels = extract_entities(text, entities)
            o_ix_map[ix] = [i for i, label in enumerate(bio_labels) if label == 'O']

        random.seed(2)
        all_o_ixs = [(ann_ix, o_ix) for ann_ix in o_ix_map for o_ix in o_ix_map[ann_ix]]
        all_o_ixs = random.sample(all_o_ixs, num_b_labels)
        keep_o_ix_map = defaultdict(set)
        for tup in all_o_ixs:
            keep_o_ix_map[tup[0]].add(tup[1])

        for ann_ix, annotation in enumerate(annotations):
            text = annotation['text']
            text_split = text.split()
            entities = annotation['entities']
            bio_labels = extract_entities(text, entities)

            result_text = []
            result_labels = []
            for i, label in enumerate(bio_labels):
                if not label.startswith('O') or i in keep_o_ix_map[ann_ix]:
                    result_labels.append(label)
                    result_text.append(text_split[i] if i < len(text_split) else '')

            kept_text = ' '.join(result_text)
            labels_str = ' '.join(result_labels)
            writer.writerow([kept_text, labels_str])

if __name__ == '__main__':
    jsonl_file_name = 'dataset.jsonl'
    csv_file_name = 'balanced_bio.csv'
    # csv_file_name = 'test.csv'
    invalid_json_file_name = 'undersampling_invalid_json_lines.txt'
    original_csv_file_name = 'ner.csv'
    convert_to_csv(jsonl_file_name, csv_file_name, invalid_json_file_name, original_csv_file_name)
